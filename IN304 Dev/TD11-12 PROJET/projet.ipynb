{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD 11 – 12\n",
    "\n",
    "**Collecte, Traitement, et Analyse de données de réseaux sociaux**\n",
    "\n",
    "On considère InPoDA, une plateforme pour l’analyse de données de réseaux sociaux. InPoDa\n",
    "est une plateforme fictive. Voici donc des hypothèses personnelles sur son fonctionnement :\n",
    "\n",
    "Lorsqu'un utilisateur rédige une publication (un tweet), elle est publiée à travers un script\n",
    "python qui vérifie d’abord la structure de l’objet tweet, le nettoie en éliminant les caractères\n",
    "spéciaux (emoji, etc.) au cas où on en a , et le stockera dans un fichier, appelé « zone\n",
    "d’atterrissage ». En pièces jointes un jeu de publications (tweets) que vous pouvez utiliser.\n",
    "N’hésitez pas à utiliser un autre jeu de tweets si vous le pensez nécessaire.\n",
    "\n",
    "Notons que à chaque lecture d’une ligne du fichier de données fournies (une ligne pourra\n",
    "correspondre à un dictionnaire Python comme il s’agit de données json), il y aura un ajout\n",
    "d’un objet tweet au fichier intitulé « zone d’atterrissage ».\n",
    "\n",
    "InPoDa propose un ensemble des opérations de traitement de données y compris:\n",
    "\n",
    "- Identification de l’auteur de la publication\n",
    "- Extraction de la liste de hashtags de la publication\n",
    "- Extraction de la liste des utilisateurs mentionnés dans la publication\n",
    "- Analyse de sentiment de la publication (le sentiment peut être positif ou bien négatif).\n",
    "Vous pouvez utiliser le module « textblob ».\n",
    "- Identification du/des topics de la publication\n",
    "\n",
    "D’autres opérations d’analyse de données sont également proposés par InPoDa :\n",
    "\n",
    "- Top K hashtags (k est un paramètre passé par l’utilisateur)\n",
    "- Top K utilisateurs\n",
    "- Top K utilisateurs mentionnés\n",
    "- Top K topics\n",
    "- Le nombre de publications par utilisateur\n",
    "- Le nombre de publications par hashtag\n",
    "- Le nombre de publications par topic\n",
    "- L’ensemble de tweets d’un utilisateur spécifique\n",
    "- L’ensemble de tweets mentionnant un utilisateur spécifique\n",
    "- Les utilisateurs mentionnant un hashtag spécifique\n",
    "- Les utilisateurs mentionnés par un utilisateur spécifique\n",
    "\n",
    "Pour avoir des résultats d’analyse de données à jours, l’analyste de données devrait être en\n",
    "mesure de déclencher l’exécution d’un processus qui consiste à récupérer les publications\n",
    "stockées dans la zone d’atterrissage et appliquer pour chaque publication l’ensemble de\n",
    "opérations de traitement de données décrites auparavant. Les résultats devraient être chargées\n",
    "dans un nouvel dataframe qui servira les opérations d’analyse de données décrites ci-dessus.\n",
    "\n",
    "Travail à faire :\n",
    "\n",
    "Le travail demandé consiste en quelques étapes principales, à savoir :\n",
    "1. Élaboration d’un diagramme qui décrit le fonctionnement de InPoDa.\n",
    "2. Prendre connaissance du sujet et plus particulièrement de la structure de données\n",
    "fournies dans le fichier de données\n",
    "3. Utiliser quand nécessaire la programmation orientée objet pour encapsuler vos\n",
    "données et traitements.\n",
    "4. Favoriser l’utilisation des expression régulières pour éviter les données malformées.\n",
    "5. Utiliser les dictionnaires pour représenter un tweet. N’hésitez pas à re-modéliser le\n",
    "dictionnaire représentant un tweet de manière à mieux répondre aux opérations\n",
    "d’analyse de données demandées\n",
    "6. Utiliser le module matplotlib pour visualier les résultats des opérations d’analyse de\n",
    "données\n",
    "\n",
    "Modalités :\n",
    "- Vous pouvez travailler en groupe de deux étudiant maximum\n",
    "- Soumettez sur l’espace dédié sur e-campus votre compte rendu, un Jupyter Notebook\n",
    "y compris les explications nécessaires.\n",
    "- L’évaluation se fait sur la base de votre compte rendu et par question/réponse par\n",
    "votre chargé de TD durant les deux dernières séances de TD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"versailles_tweets_100.json\") as tweets:\n",
    "    data =json.load(tweets)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_f_tweets = pd.DataFrame(data)\n",
    "data_f_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nettoyage du dataframe, plus important !\n",
    "import re\n",
    "\n",
    "def clean_data(dataframe):\n",
    "    clean_dataframe = dataframe.drop([\"_id\",\"id\",\"conversation_id\",\"lang\",\"created_at\",\"context_annotations\",\"attachments\"], axis=1)\n",
    "    regex_arobase = re.compile(\"@[\\w]*\")\n",
    "    regex_hashtag = re.compile(\"#[\\w]*\")\n",
    "    regex_emoji = re.compile(\"[\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"\\U000024C2-\\U0001F251\" \n",
    "    \"]+\")\n",
    "    #for i in clean_dataframe[\"text\"]:\n",
    "        #regex_arobase.sub(\" \", clean_dataframe[\"text\"][i] )\n",
    "        #dataframe.replace(to_replace={text: \" \".join(regex_arobase)}, value=\"\", regex=True, inplace=True) \n",
    "    clean_dataframe['text'] = dataframe['text'].str.replace(regex_arobase, \" \", regex=True)\n",
    "    clean_dataframe[\"text\"] = clean_dataframe[\"text\"].str.replace(regex_hashtag, \" \", regex=True)\n",
    "    clean_dataframe[\"text\"] = clean_dataframe[\"text\"].str.replace(regex_emoji, \" \", regex=True)\n",
    "\n",
    "    return clean_dataframe\n",
    "\n",
    "clean_data(data_f_tweets.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour récuperer l'ID de l'auteur du tweet\n",
    "\n",
    "def author_ID(dataframe,i):\n",
    "    return dataframe[\"author_id\"][i]\n",
    "\n",
    "print(author_ID(data_f_tweets,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour extraire la liste de #\n",
    "\n",
    "def extr_tag(dataframe,i):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour extraire la liste des utilisateurs mentionés\n",
    "\n",
    "def extr_utilMen(dataframe,i):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction d'analyse de sentiment de la publication\n",
    "\n",
    "def analySent(dataframe,i):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction d'identification du/des topics\n",
    "\n",
    "def topics(dataframe,i):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
